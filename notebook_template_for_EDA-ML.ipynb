{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Title</center></h1>\n",
    "\n",
    "<center><img src=\"\" alt=\"iIllustration\" title=\"title\"  style=\"object-fit:cover; width:800px; height:250px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __*Created by Charley lebarbier*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives :  \n",
    "*Summary of objectives*\n",
    "\n",
    "## Others :\n",
    "*May contain :* \n",
    "\n",
    "*- milestones,*  \n",
    "*- performance criteria,*  \n",
    "*- data legend,*  \n",
    "*- deliverables...*  \n",
    "\n",
    "*all useful additional information for the project*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________\n",
    "____________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>EDA - Exploratory Data Analysis</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working Environnement Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import KFold, LeaveOneOut, ShuffleSplit \n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve, validation_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier      # KNN\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset in a variable\n",
    "#\n",
    "\n",
    "# Transform if necessary\n",
    "#\n",
    "\n",
    "# Check the import\n",
    "# dataset.head()\n",
    "# dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get informations about our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information and description about our dataset\n",
    "\n",
    "#dataset.info()           # give infos about the types of each cols\n",
    "#dataset.describe()       # give infos about the stats of our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if missing value\n",
    "\n",
    "#dataset.isnull().values.any()   # True / False : give a fast answer\n",
    "#dataset.isnull().sum()       # Low -> cause calcul each value, give where data is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the amount of missing values to decide the strategy to adopt : drop or replace\n",
    "\n",
    "#sns.heatmap(file_name.isnull(), cbar=False, cmap='viridis')\n",
    "#plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning\n",
    "\n",
    "*There are two strategies: drop the missing data or replace them.*  \n",
    "*Nevertheless, it's not recommended to drop. Prefer to replace them.*  \n",
    "\n",
    "*Used the 'mean', the 'median' or the 'most frequent'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Strategy : Drop NaN\n",
    "# dataset.dropna()\n",
    "\n",
    "# Second Strategy : Replace NaN - SimpleImputer\n",
    "# imp_strat = SimpleImputer(missing_values=pd.NA, strategy='')      # mean; median; most frequent\n",
    "# imp_strat.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the modification and / or display it\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA : Asking Analytical Questions and Visualizations\n",
    "*NB: each graph need an explanation, create a markdown '__Conclusion :__' after each one or grap (of graphs)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First of all, look the correlation\n",
    "# Display a heatmap plot\n",
    "\n",
    "#sns.heatmap(dataset.corr(), cbar=True, annot=True, cmap='RdBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion about Heatmap :__\n",
    "\n",
    "- Positive(s) Correlation :  \n",
    "    - First  \n",
    "    - Second...  \n",
    "</br>\n",
    "\n",
    "- Negative(s) Correlation :  \n",
    "    - First  \n",
    "    - Second...  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pursue the analysis with the correlation and questions/reflexions you can get*  \n",
    "\n",
    "*Some goals to follow :*  \n",
    "- *Take a deeper look into the data by querying or indexing the data*  \n",
    "- *Identify features of interest*  \n",
    "- *Recognise the challenges posed by data - missing values, outliers*  \n",
    "- *Discover patterns in the data*  \n",
    "\n",
    "*Schema to follow:*  \n",
    "- *Analysis Title*  \n",
    "- *Graph*  \n",
    "- *Conclusion*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________\n",
    "#### Major Conclusions about EDA\n",
    "\n",
    "*Summarize the major insights get during the EDA and useful for the next step*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________\n",
    "____________________________________\n",
    "\n",
    "<center><h2>Machine Learning</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Dataset : Train - Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can delete the useless column(s) detected during EDA\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in 2 sets: Training / Test\n",
    "# x_train / x_test: feature ; y_train / y_test: output\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale and normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the x_train set with method : StandardScaler, MinMaxScaler, RobustScaler\n",
    "# using '.fit_transform' on it, then '.transform' on x_test\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validation\n",
    "\n",
    "*Find the best cross-validation about our problems and model:*  \n",
    "*K-Fold ; Leave One Out ; Shuffle Split ; Stratified K-Fold ; Group K-Fold*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Cross Validation Technique(s) \n",
    "#\n",
    "\n",
    "# Display score (max / min / mean) for each cross-validation technique\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Curve\n",
    "\n",
    "*Graphical technique that can be used to measure the influence of a single hyperparameter.*  \n",
    "*Like that we validate the best accuracy of our parameters for our model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a range for the test\n",
    "#\n",
    "\n",
    "# Initiate the Validation Curve\n",
    "#\n",
    "\n",
    "# Display the VC\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV\n",
    "\n",
    "*Process of performing hyperparameter tuning in order to determine the optimal values for a given model*  \n",
    "*Pass params with a dictionnary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the params' dictionnary\n",
    "#\n",
    "\n",
    "# Initiate the function\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Score\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Params\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Estimator applied on the model\n",
    "#\n",
    "\n",
    "# Use the model to predict on TestSet\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "*Used in classification problems to assess where errors in the model were made.*  \n",
    "*The rows represent the actual classes the outcomes should have been.*   \n",
    "*While the columns represent the predictions we have made.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the Confusion Matrix\n",
    "#\n",
    "\n",
    "# Display the CM\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Curve\n",
    "\n",
    "*Shows the relationship of the training score versus the cross validated test score for an estimator with a varying number of training samples. This visualization is typically used to show two things:*\n",
    "- *How much the estimator benefits from more data (e.g. do we have “enough data”)*\n",
    "- *If the estimator is more sensitive to error due to variance vs. error due to bias*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the learning Curve\n",
    "#\n",
    "\n",
    "# Display the Learning Curve\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________\n",
    "____________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2><center>Saving the Model and Params (Label Encoder and Scaler)</center></H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pickle (for OOP) or Joblib (Numpy Array / Big Data)\n",
    "# Create a file to save it -\n",
    "# Or Create a dictionnary with : Label Encoder ; Scaler ; Model\n",
    "# \n",
    "\n",
    "# Use .dump() to save\n",
    "#\n",
    "\n",
    "# Or Open an other model\n",
    "#\n",
    "\n",
    "# Use it to predict et verify the model's backup\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________\n",
    "____________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1><center>The End</center></H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>  \n",
    "<p style='text-align: right;'><i>+-+-+-+-+ Template by : Charley Lebarbier +-+-+-+-+</i></p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
